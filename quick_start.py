#!/usr/bin/env python3
"""
Quick Start Script for Video Transcript QA Dataset Generation Framework

This script demonstrates how to use the framework with a simple example.
"""

import asyncio
import os
import sys
from pathlib import Path

# Add the src directory to the Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from models import DatasetConfig, LLMConfig
from dataset_generator import DatasetGenerator


async def quick_start_demo():
    """Demonstrate the framework with a simple example."""

    print("üé¨ Video Transcript QA Dataset Generation Framework")
    print("=" * 50)

    # Check if API key is set (only needed if not using placeholder models)
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print(
            "‚ÑπÔ∏è  No OpenAI API key set. Using placeholder models for demonstration."
        )
        print(
            "   Set OPENAI_API_KEY environment variable to use real LLM models."
        )

    # Create directories
    input_dir = Path("./input_videos")
    output_dir = Path("./output_dataset")

    input_dir.mkdir(exist_ok=True)
    output_dir.mkdir(exist_ok=True)

    # Check if there are videos in the input directory
    video_files = (
        list(input_dir.glob("*.mp4"))
        + list(input_dir.glob("*.avi"))
        + list(input_dir.glob("*.mov"))
    )

    if not video_files:
        print("üìÅ No video files found in ./input_videos/")
        print(
            "Please add some video files (MP4, AVI, MOV) to the input_videos directory"
        )
        print("Then run this script again.")
        return

    print(f"üìπ Found {len(video_files)} video files")

    # Create LLM configurations
    training_llm_config = LLMConfig(
        llm_s_model="placeholder-llm-s", llm_a_model="placeholder-llm-a"
    )
    validation_llm_config = LLMConfig(
        llm_s_model="placeholder-llm-s", llm_a_model="placeholder-llm-a"
    )

    # Configuration
    config = DatasetConfig(
        input_folder=str(input_dir),
        output_folder=str(output_dir),
        segment_duration=30,
        max_concurrent_videos=2,  # Reduced for demo
        training_split_ratio=0.8,
        openai_api_base=os.getenv("OPENAI_API_BASE"),
        openai_api_key=api_key,
        training_llm_config=training_llm_config,
        validation_llm_config=validation_llm_config,
    )

    print("‚öôÔ∏è Configuration:")
    print(f"  ‚Ä¢ Input folder: {config.input_folder}")
    print(f"  ‚Ä¢ Output folder: {config.output_folder}")
    print(f"  ‚Ä¢ Segment duration: {config.segment_duration} seconds")
    print(f"  ‚Ä¢ Training LLM-S model: {config.training_llm_config.llm_s_model}")
    print(f"  ‚Ä¢ Training LLM-A model: {config.training_llm_config.llm_a_model}")
    print(
        f"  ‚Ä¢ Validation LLM-S model: {config.validation_llm_config.llm_s_model}"
    )
    print(
        f"  ‚Ä¢ Validation LLM-A model: {config.validation_llm_config.llm_a_model}"
    )
    print()

    # Create dataset generator
    print("üöÄ Initializing dataset generator...")
    generator = DatasetGenerator(config)

    try:
        # Generate dataset
        print("üîÑ Generating dataset...")
        dataset = await generator.generate_dataset(
            dataset_name="quick_start_demo",
            dataset_description="Demo dataset generated by quick start script",
        )

        # Get statistics
        stats = generator.get_dataset_statistics(dataset)

        print("\n‚úÖ Dataset generation completed!")
        print("\nüìä Results:")
        print(f"  ‚Ä¢ Total videos: {stats['total_videos']}")
        print(f"  ‚Ä¢ Total segments: {stats['total_segments']}")
        print(f"  ‚Ä¢ Training QA pairs: {stats['training_split']['qa_pairs']}")
        print(
            f"  ‚Ä¢ Validation QA pairs: {stats['validation_split']['qa_pairs']}"
        )
        print(f"  ‚Ä¢ Total QA pairs: {stats['total_qa_pairs']}")
        print(
            f"  ‚Ä¢ Training answerable without context: {stats['training_split']['is_answerable_without_context']}"
        )
        print(
            f"  ‚Ä¢ Validation answerable without context: {stats['validation_split']['is_answerable_without_context']}"
        )
        print(
            f"  ‚Ä¢ Training answerable with context: {stats['training_split']['is_answerable_with_context']}"
        )
        print(
            f"  ‚Ä¢ Validation answerable with context: {stats['validation_split']['is_answerable_with_context']}"
        )

        print(f"\nüíæ Dataset saved to: {output_dir}")
        print(f"üìÑ Main dataset file: {output_dir}/quick_start_demo.json")
        print(f"üìä HuggingFace format: {output_dir}/huggingface/")

        print("\nüéâ Quick start demo completed successfully!")

    except Exception as e:
        print(f"‚ùå Error during dataset generation: {e}")
        print("Please check your configuration and try again.")


def main():
    """Main function."""
    print(
        "Quick Start Demo for Video Transcript QA Dataset Generation Framework"
    )
    print("This script will demonstrate the framework with your video files.")
    print()

    response = input("Do you want to continue? (y/N): ").strip().lower()
    if response not in ["y", "yes"]:
        print("Demo cancelled.")
        return

    # Run the demo
    asyncio.run(quick_start_demo())


if __name__ == "__main__":
    main()
